# LLM Observability Dashboard

This project demonstrates an observability framework for monitoring Large Language Model (LLM) applications.

It tracks:
- Latency (performance)
- Token usage (resource consumption)
- Cost estimation
- Logs for traceability

A web-based dashboard visualizes these metrics to help developers understand and optimize LLM systems.

## Tech Stack
- Python
- Flask
- Pandas
- Matplotlib
- HTML/CSS

## Setup
```bash
pip install -r requirements.txt
python app.py


License: MIT License
